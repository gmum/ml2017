{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "---\n",
    "<big><big><big><big><big><big><big><big><big>Sieci neuronowe</big></big></big></big></big></big></big>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "<big><big><big><big><big>Autoenkoder</big></big></big></big></big>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "<id=tocheading><big><big><big><big>Spis treści</big></big></big></big>\n",
    "<div id=\"toc\"></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "from bokeh.io import gridplot, output_file, show\n",
    "from bokeh.plotting import figure, output_notebook\n",
    "from bokeh.charts import Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"abb17722-9013-441a-bd7d-38d2276c4c73\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      document.getElementById(\"abb17722-9013-441a-bd7d-38d2276c4c73\").textContent = \"BokehJS successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"abb17722-9013-441a-bd7d-38d2276c4c73\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'abb17722-9013-441a-bd7d-38d2276c4c73' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"abb17722-9013-441a-bd7d-38d2276c4c73\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"abb17722-9013-441a-bd7d-38d2276c4c73\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Autoenkoder\n",
    "\n",
    "to model (najczęściej sieć neuronowa), który uczy się __odtwarzać__ podawane wejście\n",
    "1. __enkoder__ $$h=f(x)$$\n",
    "2. __dekoder__ $$r=g(h)$$\n",
    "\n",
    "\n",
    "Model, który uczy się idealnie tak, że $$g(f(x))=x$$ __nie jest__ specjalnie przydatny\n",
    "\n",
    "Autoenkodery wykorzystują założenie, że dane są skupione na niżej wymiarowych rozmaitościach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## PCA - Principal Components Analysis\n",
    "* przykład prostego autoenkodera\n",
    "* PCA przetwarza wektor wejściowy $x$ na __przybliżoną__ rekonstrukcję $r$ wykorzystując __liniową__ transformację $$W^TWx$$\n",
    "<img src=\"../mum_figures/pca.png\" width=\"60%\"/>[za Ivizevic _et al._]\n",
    "  * dowolny obrót zachowuje względne relacje danych\n",
    "  * wybieramy taki obrót, który zmaksymalizuje łatwość rozróżniania danych\n",
    "    * maksymalizacja wariancji wzdłuż wynikowych kierunków głównych (_ang_. principal components)\n",
    "    * równoważne regresji __minimalizującej kwadraty odległości__ od składowych głównych\n",
    "    \n",
    "    \n",
    "    \n",
    "* w jaki sposób spojrzeć na PCA jako autoenkoder?\n",
    "  1. __enkoder__ odwzorowuje $X$ w $H$\n",
    "    * to odwzorowanie z $X$ do przestrzeni o kształcie _naleśnika_ (Bengio, Goodfellow)\n",
    "    * część współrzędnych, o najmniejszej wariancji, jest całkiem płaska i może być usunięta\n",
    "  2. __dekoder__ odwzorowuje $H$ z powrotem do $X$\n",
    "    * część informacji jest utracona\n",
    "      * ale pewnie związana z szumem\n",
    "\n",
    "\n",
    "* można spojrzeć jak na __manifold learning__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Wymiar $H$ mniejszy od wymiaru $X$\n",
    "* wymuszenie, by zachować najważniejsze informacje\n",
    "* uczenie przez minimalizację $$L(x, g(f(x)))$$\n",
    "  * jeśli dekoder liniowy a $L$ średnim błędem kwadratowym, to model równoważny PCA\n",
    "* autoenkodery z __nieliniowymi__ enkoderem i dekoderem są zatem modelami __silniejszymi__\n",
    "  * nieliniowe funkcje mają większą pojemność od liniowych\n",
    "  * jednak zbyt złożony i pojemny model może nie nauczyć się niczego!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Regularyzacja\n",
    "* modele zbyt pojemne mogą się nie nauczyć niczego\n",
    "* przestrzeń __ukryta__ (_ang_. __latent__) $H$\n",
    "* wymiar $H$ może być większy od wejściowego\n",
    "  * nawet liniowe enkoder i dekoder mogą nie nauczyć się niczego\n",
    "    * będą umiały kopiować wejście, ale żadnej wiedzy o __strukturze__ wejścia\n",
    "  * __regularyzacja__ modelu zamiast ograniczeń na wymiar i postać en-/de-koderów wymuszające\n",
    "    * rzadkość reprezentacji\n",
    "    * odporność na szum wejścia\n",
    "    * odporność na brakujące dane\n",
    "    * niską pochodną reprezentacji\n",
    "    \n",
    "    \n",
    "* także modele __generatywne__\n",
    "  * autoenkoder __wariacyjny__\n",
    "  * sieci __stochastyczne__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Autoenkoder z rzadką reprezentacją\n",
    "* głównym zadaniem jest __ wykrywanie__ (reakcja na) istotnych cech w wejściu\n",
    "* uczenie z\n",
    "\n",
    "$$L(x, g(f(x)))+\\Omega(h)$$\n",
    "gdzie $\\Omega(h)$ jest regularyzatorem dodanym do sieci \n",
    "  * kopiującej w uczeniu nienadzorowanym swoje wejście\n",
    "  * wykrywającej cechy w uczeniu nadzorowanym\n",
    "  \n",
    "* model będzie maksymalizował\n",
    "\n",
    "$$\\log\\,p_m(x, h)=\\log\\,p_m(h)+\\log_m\\,p_m(x|h)$$\n",
    "  * w ten sposób jest to model __maksymalizujący__ sznasę odzyskania $x$ przy założeniu pewnych ograniczeń na zmienne ukryte $h$\n",
    "   * warunek $\\log\\,p_m(h)$ może wymuszać __rzadką__ reprezentację, np. \n",
    "   \n",
    "   $$p_m(h_i)=\\frac{\\lambda}{2}\\exp(-\\lambda\\,|\\,h_i\\,|)$$\n",
    "   \n",
    "* rzadka reprezentacja\n",
    "  * nie jest czynnikiem regularyzacyjnym, ale\n",
    "  * wymusza uczenie zmiennych ukrytych, które __tłumaczą__ wejście\n",
    "  \n",
    "  \n",
    "  \n",
    "* użycie $\\Omega(h)$ jak wyżej\n",
    "  * nie zapewnia ścisłej rzadkiej reprezentacji\n",
    "  * uzyskanie rzeczywistych zer możliwe przez użycie dodatkowo aktywacji ReLU\n",
    "    * pozwala uzyskać roprezentację z ustaloną liczbą zer\n",
    "    * możliwe użycie _softmax_ na warstwie ukrytej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Autoenkodery odszumiające\n",
    "* użycie kosztu\n",
    "\n",
    "$$L(x, g(f(\\tilde{x})))$$\n",
    "gdzie $\\tilde{x}$ jest zaszumionym wejściem\n",
    "* zadaniem jest _usuwanie_ szumu\n",
    "  * domyślnie uczy się struktury danych\n",
    "  <img src=\"../mum_figures/DAE.png\" width=\"100%\"/>[za Bengio _et al_.]\n",
    "  \n",
    "  \n",
    "  \n",
    "1. losowanie przykładu $x$ ze danych uczących\n",
    "2. losowanie danych zaburzonych $\\tilde{x}$ z $Z(\\tilde{x}\\mid x)$\n",
    "3. użycie $(\\tilde{x},x)$ jako danej uczącej\n",
    "  * odtwarzanie z $$p(x\\mid\\tilde{x})=p(x\\mid h)$$\n",
    "  gdzie zmienna ukryta $h=f(\\tilde{x})$\n",
    "4. dekoder $g(h)$\n",
    "\n",
    "\n",
    "* uczenie gradientowe przez minimalizację log-likelihood $-\\log\\,p(x\\mid h=f(\\tilde{x}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Uczenie rozmaitości\n",
    "Autoenkodery mają zapewniać __jednocześnie__\n",
    "1. uczenie reprezentacji $h=f(x)$ takiej, że\n",
    "  * $x$ można odtworzyć\n",
    "  * dane losowane są z danych uczących\n",
    "    * autoenkoder nie musi poprawnie odtwarzać danych spoza rozkładu\n",
    "2. zapewnienie ograniczeń\n",
    "  * ograniczenia architektury ograniczające pojemność\n",
    "  * czynniki regularyzacyjne ograniczające wrażliwość na szum\n",
    "  \n",
    "  \n",
    "\n",
    "* reprezentacja ukryta opisuje strukturę generującą dane\n",
    "  * enkoder tworzy reprezentację odwzorowującą geometrię nisko-wymiarowej rozmaitości gdzie znajdują się dane\n",
    "  * samo kopiowanie wejścia __nie jest__ istotne\n",
    "  \n",
    "  <img src=\"../mum_figures/manifold.png\" width=\"100%\"/>\n",
    "* metody uczenia manifoldów oparte na metodach sąsiadów\n",
    "  * tworzą graf sąsiadów\n",
    "  * jeśli przykładów jest wystarczająco wiele\n",
    "    * pojedyncze przykłady można uogólnić do \"płaskich\" gausianów\n",
    "    * to pozwoli odtworzyć geometrię rozmaitości\n",
    "    * możliwe będzie generowanie nowych danych przez uśrednianie między obszarami przykładów\n",
    "* jeśli rozmaitości __nie są__ gładkie\n",
    "  * będzie potrzebna duża liczba przykładów w okolicach każdego zaburzenia gładkości\n",
    "  * generowanie będzie utrudnione\n",
    "    * możliwe jedynie pomiędzy bliskimi sąsiadami\n",
    "\n",
    "* powinno pomóc uzycie głębokich autoenkoderów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Autoenkoder wariacyjny\n",
    "* autoenkodery znajdują odwzorowanie $x\\longrightarrow\\,h$\n",
    "* model wariacyjny pozwala na odwzorowanie $x$ w __rozkład__ $\\mathcal{N}(\\mu,\\sigma^2)$ w przestrzeni ukrytej\n",
    "  * to pozwala na __próbkowanie__ z rozkładu normalnego\n",
    "    * model losuje z rozkładu $p_m(z)$\n",
    "    * tworzy $x'=g(z)$\n",
    "* model wariacyjny __maksymalizuje__\n",
    "\n",
    "$$L(q)=E_{z\\tilde\\,q(z\\mid x)}\\log\\,p_m(z,x)+H(q(z\\mid x))$$\n",
    "  * model składa się z __enkodera__ $q(z\\mid x)$ tworzącego $z$\n",
    "  * oraz __dekodera__ $p_m(x\\mid z)$\n",
    "  * pierwszy składnik maksymalizuje całkowite prawdopodobieństwo zmiennych ukrytych i widzialnych\n",
    "  * drugi jest entropią $q$\n",
    "    * $q$ jest (może być) zwykle gausowski\n",
    "    * maksymalizacja entropii zachęca model do skupianiu się na __wielu__ wartościach $z$, które mogą wygenerować $x$, a nie tylko na jednej\n",
    "    * to jest odmienne od modelu mapowania punkt w punkt\n",
    "\n",
    "\n",
    "* autoenkoder wariacyjny może być łatwo nauczony\n",
    "  * możliwe jest wiele architektur enkodera i dekodera\n",
    "    * wszystkie warstwowe\n",
    "    * enkoder warstwowy a dekoder rekurencyjny\n",
    "    * obie rekurencyjne\n",
    "\n",
    "---\n",
    "<img src=\"../mum_figures/vae-faces.png\" width=\"100%\"/>[za Bengio et al]\n",
    "* twarze na rysunku __wygenerowane__\n",
    "* przestrzeń ukryta w 2 wymiarach\n",
    "  * oś pozioma wyraźnie odpowiada obrotowi\n",
    "  * oś pionowa wyrazowi twarzy\n",
    "---\n",
    "    \n",
    "* wygenerowane przykłady z nauczonego autoenkodera mają tendencję by być nieco _zamazane_ (_ang_. blurry) [Bengio _et al_.]\n",
    "  * nie są znane jeszcze powody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
