{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uczenie gradientowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rozbicie warstw na warstwę liniową oraz warstwę aktywacji\n",
    "\n",
    "Tradycyjnie przez neuron rozumie się funkcję\n",
    "$$o(x) = a(<x,w> + b)$$\n",
    "gdzie $w$ to wagi, $b$ to bias, natomiast $a$ to funkcja aktywacji. Grupa neuronów mających wspólne wejście $x$ tworzy warstwę sieci neuronowej.\n",
    "\n",
    "<img src=\"figures/L10/nn.png\" width=600>\n",
    "\n",
    "Znacznie wygodniej jest rozumieć warstwy tak, jak w bibliotece *keras*, tzn. rozważając oddzielnie część liniową i funkcję aktywacji. Wtedy neuron w tradycyjnym rozumieniu jest tak naprawdę parą kolejnych neuronów\n",
    "$$o(x) = o_2(o_1(x))$$\n",
    "$$o_1(x) = <x|w> + b$$\n",
    "$$o_2(x) = a(x)$$\n",
    "\n",
    "<img src=\"figures/L10/nn_extended.png\" width=600>\n",
    "\n",
    "Neurony liniowe tworzą warstwę *Dense* (połączenia typu \"każdy z każdym\" pomiędzy wejściem i wyjściem) sparametryzowaną macierzą wag $W$, natomiast neurony aktywacji tworzą warstwę aktywacji (połączenia typu \"jeden do jeden\") i warstwa ta nie posiada żadnych wag.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uczenie metodami gradientowymi\n",
    "\n",
    "Najprostszy algorytm uczenia sieci neuronowej:\n",
    "1. Inicjalizujemy wagi (np. losowo).\n",
    "2. W pętli:\n",
    "    1. Obliczamy wartość funkcji kosztu.\n",
    "    2. Dokonujemy losowej modyfikacji wag i ponownie obliczamy wartość funkcji kosztu:\n",
    "        1. Jeśli uległa ona zmniejszeniu, zmieniamy wagi na nowe.\n",
    "        2. Jeśli uległa zwiększeniu, zostajemy przy starych wagach.\n",
    "\n",
    "Powyższy algorytm ma poważną wadę: losowa modyfikacja bardzo dużej liczby parametrów (w wypadku sieci neuronowych są to liczby rzędu kilku milionów) spowoduje niewielką zmianę funkcji kosztu - intuicyjnie możemy myśleć, że zmiany spowodowane przez modyfikację kolejnych parametrów będą się wzajemnie kasować.\n",
    "\n",
    "Metody gradientowe działają następująco:\n",
    "1. Inicjalizujemy wagi (np. losowo).\n",
    "2. W pętli:\n",
    "    1. Dla każdego parametru sieci obliczamy, jak silny jest jego wpływ na wartość funkcji kosztu.\n",
    "    2. Na tej podstawie modyfikujemy parametry.\n",
    "\n",
    "Szczegóły kroku 2B zależą od konkretnej metody. \n",
    "\n",
    "Przez siłę wpływu parametru sieci neuronowej na wartość funkcji kosztu rozumiemy pochodną cząstkową $\\frac{\\partial L}{\\partial\\theta}$, gdzie $\\theta$ jest dowolnym parametrem (wagą), a $L$ funkcją kosztu, która zależy od parametrów sieci i elementów zbioru treningowego. Taka definicja ma sens, ponieważ (powtórka z analizy matematycznej):\n",
    "$$L(\\ldots, \\theta + \\Delta\\theta, \\ldots) \\approx L(\\ldots, \\theta, \\ldots) + \\frac{\\partial L}{\\partial\\theta}\\Delta\\theta$$\n",
    "a więc zmiana parametru $\\theta$ o $\\Delta\\theta$ spowoduje $\\frac{\\partial L}{\\partial\\theta}$ razy większą zmianę kosztu $L$.\n",
    "\n",
    "Najefektywniej modyfikować parametry **proporcjonalnie do siły ich wpływu**, ponieważ wtedy poruszamy się w kierunku najszybszej zmiany wartości funkcji $L$. Kierunek ten wyznaczony jest (minus) gradientem funkcji $L$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wpływ pojedynczego neuronu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/L10/single_neuron.png\" width=430>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby obliczyć wpływ neuronu na wartość funkcji kosztu musimy:\n",
    "1. obliczyć wpływ tego neuronu na kolejne neurony,\n",
    "2. obliczyć wpływ kolejnych neuronów na wartość funkcji kosztu.\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial o} = \\frac{\\partial L}{\\partial o_1}\\frac{\\partial o_1}{\\partial o} + \\frac{\\partial L}{\\partial o_2}\\frac{\\partial o_2}{\\partial o} + \\frac{\\partial L}{\\partial o_3}\\frac{\\partial o_3}{\\partial o}$$\n",
    "\n",
    "Jak rozumieć powyższy wzór:\n",
    "* jeśli np. $\\frac{\\partial L}{\\partial o_1} = 2$, oznacza to, że mała zmiana $o_1$ spowoduje dwukrotnie większą zmianę $L$,\n",
    "* jeśli np. $\\frac{\\partial o_1}{\\partial o} = 3$, oznacza to, że mała zmiana $o$ spowoduje trzykrotnie większą zmianę $o_1$,\n",
    "* łącząc dwa powyższe fakty wnioskujemy, że mała zmiana $o$ spowoduje sześciokrotnie (trzy razy dwa) większą zmianę $L$, stąd mnożenie $\\frac{\\partial L}{\\partial o_1}\\frac{\\partial o_1}{\\partial o}$,\n",
    "* skoro $o$ wpływa bezpośrednio na $o_1$, $o_2$ i $o_3$, to zmiany wartości $L$ spowodowane przez $o$ przy pomocy  $o_1$, $o_2$ i $o_3$ należy zsumować,\n",
    "* $o$ nie wpływa na $L$ w żaden inny sposób, dlatego po prawej stronie równości $\\frac{\\partial L}{\\partial o} = \\frac{\\partial L}{\\partial o_1}\\frac{\\partial o_1}{\\partial o} + \\frac{\\partial L}{\\partial o_2}\\frac{\\partial o_2}{\\partial o} + \\frac{\\partial L}{\\partial o_3}\\frac{\\partial o_3}{\\partial o}$ nie ma nic więcej.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/L10/single_neuron_paths.png\" width=430>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeszcze inaczej - powyższy wzór opisuje wszystkie (skierowane) ścieżki, którymi możemy dostać się z $o$ do $L$:\n",
    "* $\\frac{\\partial L}{\\partial o}$ - wszystkie ścieżki z $o$ do $L$,\n",
    "* $\\frac{\\partial L}{\\partial o_1}$ - wszystkie ścieżki z $o_1$ do $L$,\n",
    "* $\\frac{\\partial L}{\\partial o_2}$ - wszystkie ścieżki z $o_2$ do $L$,\n",
    "* $\\frac{\\partial L}{\\partial o_3}$ - wszystkie ścieżki z $o_3$ do $L$,\n",
    "* $\\frac{\\partial o_1}{\\partial o}$ - wszystkie ścieżki (w tym wypadku dokładnie jedna) z $o$ do $o_1$,\n",
    "* $\\frac{\\partial o_2}{\\partial o}$ - wszystkie ścieżki (w tym wypadku dokładnie jedna) z $o$ do $o_2$,\n",
    "* $\\frac{\\partial o_3}{\\partial o}$ - wszystkie ścieżki (w tym wypadku dokładnie jedna) z $o$ do $o_3$.\n",
    "\n",
    "Mnożenie to konkatenacja ścieżek (każda z każdą), dodawanie to suma zbiorów ścieżek. Jeśli po dwóch stronach równości są te same zbiory ścieżek, to równość jest prawdziwa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wpływ pojedynczej wagi\n",
    "\n",
    "<img src=\"figures/L10/single_neuron_weight.png\" width=430>\n",
    "\n",
    "Aby obliczyć wpływ wagi na wartość funkcji kosztu musimy:\n",
    "1. obliczyć wpływ tej wagi na kolejny neuron (zawsze jest dokładnie jeden),\n",
    "2. obliczyć wpływ kolejnego neuronu na wartość funkcji kosztu.\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w_1} = \\frac{\\partial L}{\\partial o_1}\\frac{\\partial o_1}{\\partial w_1}$\n",
    "\n",
    "Powyższy wzór również możemy rozumieć jako zbiór wszystkich ścieżek z krawędzi $w_1$ do $L$ zapisany na dwa różne sposoby.\n",
    "\n",
    "Przechodząc wstecz przez warstwę aktywacji pomijamy krok opisany w tej sekcji, ponieważ warstwy aktywacji nie mają parametrów (wag)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wpływ neuronów z najwyższej warstwy\n",
    "\n",
    "Neurony z najwyższej warstwy są bezpośrednio połączone z węzłem obliczającym wartość funkcji kosztu $L$, więc pochodne cząstkowe $\\frac{\\partial L}{\\partial o}$ liczymy wprost ze wzoru na $L$. Jeśli definiujemy\n",
    "$$L(y_{true}, y_{pred}) = \\ldots$$\n",
    "to pamiętamy, że $o = y_{pred}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metryka vs funkcja kosztu\n",
    "\n",
    "Metryka - to, co faktycznie chcemy optymalizować.\n",
    "\n",
    "Funkcja kosztu - różniczkowalna funkcja, którą chcemy minimalizować.\n",
    "\n",
    "Jeśli metryka jest różniczkowalna, to używamy jej jako funkcji kosztu (być może po drobnych modyfikacjach, aby optymalizacja polegała na minimalizacji). Jeśli nie, to dobieramy funkcję kosztu tak, aby jej minimalizacja przybliżała optymalizację metryki.\n",
    "\n",
    "Przykład - problem klasyfikacji binarnej:\n",
    "\n",
    "Nie możemy użyć accuracy jako funkcji kosztu, bo jest ona nieróżniczkowalna. Minimalizacja crossentropy dość sensownie przybliża maksymalizowanie accuracy, więc jest uzasadnione użycie jej jako funkcji kosztu. Oczywiście mogą się zdarzyć przypadki, że zmniejszenie crossentropy pogorszy accuracy, ale z reguły tak nie będzie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "Backpropagation to algorytm efektywnego liczenia siły wpływu poszczególnych neuronów oraz wag sieci neuronowej na wartość funkcji kosztu. Polega on na obliczaniu $\\frac{\\partial L}{\\partial o}$ oraz $\\frac{\\partial L}{\\partial w}$ warstwa po warstwie, zaczynając od najwyższej.\n",
    "\n",
    "Pytanie kontrolne - dlaczego nie zaczynamy od najniższej warstwy? \n",
    "\n",
    "We wzorach na pochodne cząstkowe mogą pojawić się wartości innych wag (literka $w$ z indeksami) oraz wartości zwracane przez inne neurony (literka $o$ z indeksami). Wagi już mamy, natomiast wartości neuronów trzeba przeliczyć dla każdego przykładu treningowego $(\\mathbf{x},y)$ - w tym celu wykonujemy tzw. *forward pass*, czyli po prostu wstawiamy $\\mathbf{x}$ na wejściu sieci i liczymy warstwa po warstwie od dołu.\n",
    "\n",
    "Pytanie kontrolne - dlaczego nie zaczynamy od najwyższej warstwy?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
