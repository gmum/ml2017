{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notacja\n",
    "\n",
    "* Mała literka - oznacza liczbę, np. $y$.\n",
    "* Pogrubiona mała literka - wektor liczb, np. $\\mathbf{x}$.\n",
    "* Pogrubiona duża literka - dwuwymiarowa tablica liczb, np. $\\mathbf{X}$.\n",
    "* Literka z dolnym indeksem i, j lub podobną - oznacza i-tą obserwację (i-ty przykład) albo i-tą współrzędną wektora; trzeba zgadywać z kontekstu.\n",
    "\n",
    "\n",
    "* Cechy oznaczamy z reguły literką x.\n",
    "* Wartości, etykiety oznaczamy z reguły literkami y lub t (jak \"target\").\n",
    "* Wagi oznaczamy literką w.\n",
    "* Literka b z reguły oznacza bias.\n",
    "\n",
    "\n",
    "* $\\boldsymbol{\\phi}$ oznacza zmianę zmiennych, jednego wektora $\\mathbf{x}$; wektor po zmianie zmiennych może mieć inną długość.\n",
    "* $\\mathbf{\\Phi}$ również oznacza zmianę zmiennych, ale całej tabeli $\\mathbf{X}$; tabela po zmianie zmiennych musi mieć tę samą wysokość (tyle samo przykładów), ale może zmienić się jej szerokość."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozkład na rozkładach - jakie tu są rozkłady?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zakładamy, że nasze dane (każda obserwacja jest postaci $(\\mathbf{x}, y)$) pochodzą z rozkładu łącznego $P_{\\mathbf{w}}$ dla pewnego prawdziwego $\\mathbf{w}$.\n",
    "\n",
    "<img src=\"figures/L2/linear_reg.png\">\n",
    "\n",
    "Przy ustalonej zmianie zmiennych każdy taki rozkład jest jednoznacznie opisany wagami $\\mathbf{w}$, stąd rozkład $\\mathcal{P}$ jest rozkładem na przestrzeni wag - uczymy się $\\mathcal{P}(\\mathbf{w})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie regresji liniowej\n",
    "\n",
    "Załóżmy, że zakończyliśmy uczenie i mamy rozkład łączny dany wzorem PPD:\n",
    "\n",
    "$$p(\\mathbf{x}, y) = \\int_{\\mathbf{w}} p(\\mathbf{x}, y|\\mathbf{w}) \\, \\mathcal{P}(\\mathbf{w}|(\\mathbf{X}, \\mathbf{y}),\\mathrm{prior}) \\operatorname{d}\\!\\mathbf{w}$$\n",
    "\n",
    "lub w wersji uproszczonej MAP lub ML:\n",
    "\n",
    "$$p(\\mathbf{x}, y) = p(\\mathbf{x}, y|\\tilde{\\mathbf{w}}) = P_{\\tilde{\\mathbf{w}}}(\\mathbf{x}, y)$$\n",
    "\n",
    "Zadanie regresji liniowej polega na odgadnięciu $\\hat y$ przy pewnym danym $\\mathbf{\\hat x}$. Rozkład $\\hat y$ opisany jest następująco:\n",
    "\n",
    "$$p(y) = p(\\mathbf{x}, y| \\mathbf{x} = \\mathbf{\\hat x})$$\n",
    "\n",
    "Na rysunku w poprzedniej sekcji oznacza to, że poziomo ustalamy $\\mathbf{\\hat x}$ i rozkład opisujący $\\hat y$ to jedna z \"górek\" nad przerywanymi liniami.\n",
    "\n",
    "Ważna uwaga: dla tego samego zestawu cech, $\\mathbf{x}$, mogą w rzeczywistości pojawiać się różne wartości $y$ - np. ten sam sprzęt komputerowy, o tych samych parametrach, w różnych sklepach może mieć różną cenę.\n",
    "\n",
    "My z powyższego rozkładu musimy wybrać jedną konkretną wartość. Jeśli chcemy minimalizować błąd średniokwadratowy (mean squared error, MSE), to najbardziej opłaca się wybrać średnią rozkładu. Ale gdybyśmy np. chcieli przewidzieć cenę produktu i ograniczyć ryzyko, że podamy zbyt niską wartość, do $10\\%$, to należy wybrać kwantyl rzędu $0.9$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Założenia regresji liniowej\n",
    "\n",
    "Dla pewnego ustalonego, nieznanego $\\mathbf{w}$ zachodzi:\n",
    "\n",
    "$$ p(y | \\mathbf{x}) = N(<\\mathbf{x}, \\mathbf{w}>, \\sigma^2) = <\\mathbf{x}, \\mathbf{w}> + N(0, \\sigma^2) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zmiana zmiennych\n",
    "\n",
    "$$ p(y | \\mathbf{x}) = N(<\\boldsymbol{\\phi}(\\mathbf{x}), \\mathbf{w}>, \\sigma^2) = <\\boldsymbol{\\phi}(\\mathbf{x}), \\mathbf{w}> + N(0, \\sigma^2) $$\n",
    "\n",
    "gdzie\n",
    "\n",
    "$$\\boldsymbol{\\phi}(\\mathbf{x}) = ({\\phi_0(\\mathbf{x}),\\phi_1(\\mathbf{x}), \\ldots,\\phi_{M-1}(\\mathbf{x})\\\\})$$\n",
    "\n",
    "to tzw. funkcje bazowe.\n",
    "\n",
    "Uwaga - przy zmianie zmiennych wartość i długość prawdziwego wektora $\\mathbf{w}$ może ulec zmianie.\n",
    "\n",
    "Funkcja $\\boldsymbol{\\phi}$ musi być zdefiniowana ręcznie i nie ulega zmianie podczas uczenia (regresja liniowa jest stosunkowo prostym modelem). Za to sieci neuronowe potrafią się jej uczyć.\n",
    "\n",
    "Jeśli umiemy rozwiązać problem regresji liniowej, to umiemy też w prosty sposób rozwiązać problem regresji liniowej ze zmianą zmiennych. Robimy to w następujący sposób:\n",
    "1. Uczenie:\n",
    "  * zamieniamy $\\mathbf{X}$ na $\\mathbf{\\Phi}$,\n",
    "  * uczymy się zwykłego liniowego modelu na $(\\mathbf{\\Phi}, \\mathbf{y})$.\n",
    "2. Predykcja:  \n",
    "  * zamieniamy $\\mathbf{x}$ na $\\boldsymbol{\\phi}$,\n",
    "  * przewidujemy wartość $y$ nauczonym liniowym modelem, podając mu $\\boldsymbol{\\phi}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estymator ML\n",
    "\n",
    "Gdzie zajrzeć:\n",
    "* książka Bishopa,\n",
    "* np. tu: https://www.statlect.com/fundamentals-of-statistics/linear-regression-maximum-likelihood\n",
    "\n",
    "W drugim linku pojawiają się tylko troszkę inne oznaczenia:\n",
    "* wagi oznaczane są przez $\\beta$,\n",
    "* szum gaussowski oznaczany jest przez $\\epsilon$.\n",
    "\n",
    "Można tam śmiało opuścić sekcję \"Asymptotic variance\".\n",
    "\n",
    "Ostatecznie otrzymujemy wzór na wagi:\n",
    "$$ \\hat \\beta_N = (X^TX)^{-1}X^Ty$$\n",
    "\n",
    "co przy naszych oznaczeniach zapisujemy jako:\n",
    "$$ \\mathbf{w} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$\n",
    "\n",
    "a w wersji ze zmianą zmiennych (patrz poprzednia sekcja) jako:\n",
    "$$ \\mathbf{w} = (\\mathbf{\\Phi}^T\\mathbf{\\Phi})^{-1}\\mathbf{\\Phi}^T\\mathbf{y}$$\n",
    "\n",
    "Parametr $\\sigma$ opisuje tylko błąd gaussowski - w naszych przewidywaniach zawsze pomijamy szum, więc jego wartość nie jest nam potrzebna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estymator MAP\n",
    "\n",
    "Gdzie zajrzeć:\n",
    "* książka Bishopa,\n",
    "* https://en.wikipedia.org/wiki/Bayesian_linear_regression - koszmarne wzory,\n",
    "* np. tu: https://www.cs.utah.edu/~fletcher/cs6957/lectures/BayesianLinearRegression.pdf\n",
    "\n",
    "W ostatnim linku znów wagi oznaczone są przez $\\beta$.\n",
    "\n",
    "Okazuje się, że jeśli założymy dwie rzeczy:\n",
    "* szum gaussowski ma stałą wariancję równą $\\sigma^2$,\n",
    "* wagi $\\mathbf{w}$ mają rozkład a priori $N(0, \\lambda^{-1}I)$, $I$ to macierz identycznościowa,\n",
    "\n",
    "to można policzyć jawnym wzorem rozkład a posteriori na wagach i będzie to również rozkład normalny o średniej:\n",
    "\n",
    "$$ \\mu = (\\mathbf{X}^T\\mathbf{X} + \\sigma^2 \\lambda I)^{-1}\\mathbf{X}^T\\mathbf{y} $$\n",
    "\n",
    "a ponieważ jest to rozkład normalny, to jego gęstość osiąga w średniej maksimum, więc jego średnia jest estymatorem MAP:\n",
    "\n",
    "$$ \\mathbf{w} = (\\mathbf{X}^T\\mathbf{X} + \\sigma^2 \\lambda I)^{-1}\\mathbf{X}^T\\mathbf{y} $$\n",
    "\n",
    "oraz w wersji ze zmianą zmiennych:\n",
    "\n",
    "$$ \\mathbf{w} = (\\mathbf{\\Phi}^T\\mathbf{\\Phi} + \\sigma^2 \\lambda I)^{-1}\\mathbf{\\Phi}^T\\mathbf{y} $$\n",
    "\n",
    "Gdy $\\lambda$ dąży do zera, to rozkład a priori \"wypłaszcza się\" do nieskończoności - oznacza to, że żadne wagi nie są dla nas a priori bardziej prawdopodobne. Zauważmy, że wtedy ML == MAP, co ma sens, ponieważ cała wiedza pochodzi z funkcji likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteracyjny ML i MAP\n",
    "\n",
    "Wróćmy do linku https://www.statlect.com/fundamentals-of-statistics/linear-regression-maximum-likelihood , a konkretnie do dowodu w sekcji \"The maximum likelihood estimators\".\n",
    "\n",
    "W wyprowadzeniu wzoru na wagi pojawia się gradient log-likelihood względem wag, oznaczony jako $\\nabla_\\beta$ (u nas byłby oznaczony $\\nabla_\\mathbf{w}$). Interesuje nas takie dobranie wag, żeby zmaksymalizować log-likelihood, a w takim razie wystarczy znaleźć wagi, dla których gradient jest zerem - stąd bierze się jawny wzór na $\\mathbf{w}$.\n",
    "\n",
    "Ale możemy też chcieć uczyć się iteracyjnie, tzn. rozpocząć od ustalenia dowolnych wag $\\mathbf{w}$ i wykonać wielokrotnie przypisanie:\n",
    "$$ \\mathbf{w} \\leftarrow \\mathbf{w} + \\mathrm{lr}\\nabla_\\mathbf{w}$$\n",
    "gdzie $\\mathrm{lr}$ to tzw. learning rate, a cały proces nazywamy Stochastic Gradient Ascent. Więcej tu (i wkrótce na wykładzie):\n",
    "* https://en.wikipedia.org/wiki/Stochastic_gradient_descent\n",
    "* http://stackoverflow.com/questions/22594063/what-is-the-difference-between-gradient-descent-and-gradient-ascent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
