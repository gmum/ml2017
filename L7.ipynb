{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L7: Klasyfikacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na dzisiejszych ćwiczeniach skupimy się na: \n",
    "\n",
    "1. Ewaluacji klasyfikatorów i modeli probabilistycznych na przykładzie rozpoznawania raka piersi\n",
    "2. Różnicach pomiędzy Naive Bayes z regresja logistyczną\n",
    "3. Praktycznym problemie klasyfikacji SPAMu (od wczytania danych do klasyfikatora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import cPickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.learning_curve import learning_curve\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metryki (klasyfikator binarny)\n",
    "\n",
    "Przypomnijmy, że zadaniem uczenia maszynowego jest znalezienie modelu, który minimalizuje loss na zbiorze testowym (notebooki L5 oraz L6). Tutaj zajmujemy się definicjami metryk, z których każda także może być funkcją kosztu.\n",
    "\n",
    "<img width=300 src=\"wyklady2017/mum_figures/precision_recall.png\">\n",
    "\n",
    "Niech $y$ to prawdziwa klasa, a $\\hat{y}$ to predykcja. Najpopularniejsze metryki dla klasyfikatorów binarnych:\n",
    "\n",
    "* Accuracy\n",
    "\n",
    "$$ \\frac{TP + TN}{TN + FN + TP + FP} = p(\\hat{y} = y | x) $$\n",
    "\n",
    "* Precision \n",
    "\n",
    "$$ \\frac{TP}{TP + FP} = p(y=1| \\hat{y}=1) $$\n",
    "\n",
    "* Recall \n",
    "\n",
    "$$ \\frac{TP}{TP + FN} = p(\\hat{y}=1| y=1) $$\n",
    "\n",
    "## Imbalans klas\n",
    "\n",
    "Ref: https://svds.com/learning-imbalanced-classes/\n",
    "\n",
    "Chcemy zdefiniować metryki *zbalansowane*. Przez zbalansowaną metrykę rozumiemy metrykę jak najmniej wrażliwą na \"prior\" klas. [Wytłumaczyć czemu accuracy jest mylące]\n",
    "\n",
    "## Bardziej zaawansowane metryki\n",
    "\n",
    "Kolejne metryki (dla klasyfikatorów binarnych) będą oparte o confusion matrix:\n",
    "\n",
    "<img src=\"figures/L7/confusion_matrix.png\">\n",
    "\n",
    "### Balanced accuracy\n",
    "\n",
    "$$ \\frac{\\mbox{precision} + \\mbox{recall}}{2} $$\n",
    "\n",
    "Idea: Zbalansowana metryka, średnia precision i recall.\n",
    "\n",
    "Problemy:\n",
    "1. nie używa w ogóle TN. \n",
    "2. zwraca wysoki wynik dla danych typu duża przewaga pozytywnych klas i model zwracający zawsze pozytywną klasę (recall i precision wysokie)\n",
    "\n",
    "### F1\n",
    "\n",
    "$$ \\frac{\\mbox{precision} * \\mbox{recall}}{\\mbox{precision} + \\mbox{recall}} $$\n",
    "\n",
    "Idea: Zbalansowana metryka, średnia *harmoniczna* precision i recall.\n",
    "\n",
    "Problemy:\n",
    "1. nie używa w ogóle TN. \n",
    "2. zwraca wysoki wynik dla danych typu duża przewaga pozytywnych klas i model zwracający zawsze pozytywną klasę (recall i precision wysokie)\n",
    "\n",
    "### Matthews correlation coefficient\n",
    "\n",
    "$$ \\frac{TP*TN  - FP*FN}{\\sqrt{(TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)}} $$\n",
    "\n",
    "Idea: Zbalansowana metryka, która używa całej macierzy confusion.\n",
    "\n",
    "Plus: bardziej \"odporna\" na \"głupie\" klasyfikatory.\n",
    "\n",
    "## Funkcja kosztu\n",
    "\n",
    "Na podstawie confusion matrix możemy definiować funkcję kosztu. Ile płacimy za FN? W przypadku klasyfikacji raka, dużo \"tańsze\" jest skierowanie pacjenta na dodatkowe badania niż postawienie fałszywej negatywnej diagnozy!\n",
    "\n",
    "<img width=400 src=\"figures/L7/cost_mat.png\">\n",
    "\n",
    "Oczywiście zazwyczaj $C_{TP}$ oraz $C_{TN}$ jest 0. Funkcja kosztu 0-1 (albo accuracy) odtwarza $C_{FN} = C_{FP}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasyfikacja wrażliwa na koszt\n",
    "\n",
    "Ref: http://web.cs.iastate.edu/~honavar/elkan.pdf\n",
    "\n",
    "Czasami jesteśmy bardziej zainteresowani w precision lub recall. Są to problemy ``cost-sensitive``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>0.372583</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>0.483918</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "count  5.690000e+02  569.000000   569.000000    569.000000      569.000000   \n",
       "mean   3.037183e+07    0.372583    14.127292     19.289649       91.969033   \n",
       "std    1.250206e+08    0.483918     3.524049      4.301036       24.298981   \n",
       "min    8.670000e+03    0.000000     6.981000      9.710000       43.790000   \n",
       "25%    8.692180e+05    0.000000    11.700000     16.170000       75.170000   \n",
       "50%    9.060240e+05    0.000000    13.370000     18.840000       86.240000   \n",
       "75%    8.813129e+06    1.000000    15.780000     21.800000      104.100000   \n",
       "max    9.113205e+08    1.000000    28.110000     39.280000      188.500000   \n",
       "\n",
       "         area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "count   569.000000       569.000000        569.000000      569.000000   \n",
       "mean    654.889104         0.096360          0.104341        0.088799   \n",
       "std     351.914129         0.014064          0.052813        0.079720   \n",
       "min     143.500000         0.052630          0.019380        0.000000   \n",
       "25%     420.300000         0.086370          0.064920        0.029560   \n",
       "50%     551.100000         0.095870          0.092630        0.061540   \n",
       "75%     782.700000         0.105300          0.130400        0.130700   \n",
       "max    2501.000000         0.163400          0.345400        0.426800   \n",
       "\n",
       "       concave points_mean           ...             radius_worst  \\\n",
       "count           569.000000           ...               569.000000   \n",
       "mean              0.048919           ...                16.269190   \n",
       "std               0.038803           ...                 4.833242   \n",
       "min               0.000000           ...                 7.930000   \n",
       "25%               0.020310           ...                13.010000   \n",
       "50%               0.033500           ...                14.970000   \n",
       "75%               0.074000           ...                18.790000   \n",
       "max               0.201200           ...                36.040000   \n",
       "\n",
       "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128          0.132369   \n",
       "std         6.146258        33.602542   569.356993          0.022832   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.080000        84.110000   515.300000          0.116600   \n",
       "50%        25.410000        97.660000   686.500000          0.131300   \n",
       "75%        29.720000       125.400000  1084.000000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       compactness_worst  concavity_worst  concave points_worst  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean            0.254265         0.272188              0.114606   \n",
       "std             0.157336         0.208624              0.065732   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.147200         0.114500              0.064930   \n",
       "50%             0.211900         0.226700              0.099930   \n",
       "75%             0.339100         0.382900              0.161400   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       symmetry_worst  fractal_dimension_worst  \n",
       "count      569.000000               569.000000  \n",
       "mean         0.290076                 0.083946  \n",
       "std          0.061867                 0.018061  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250400                 0.071460  \n",
       "50%          0.282200                 0.080040  \n",
       "75%          0.317900                 0.092080  \n",
       "max          0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/L7/data.csv\")\n",
    "data.drop(\"Unnamed: 32\",axis=1,inplace=True)\n",
    "data['diagnosis']=data['diagnosis'].map({'M':1,'B':0})\n",
    "data.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1166dae90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAFVCAYAAADPM8ekAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGYBJREFUeJzt3X1sk/fd7/GPHdtAYqd0k5GqjuIuzVQeorImRZxFzbIq\nqYLK1Adwm6QxQkRt07NObJ42khIIMDoeNkq1A0h0SJUapJD0FAYHaQ+KIoYEqCDOICts0VGTlolV\n3AkwYpsmdsh1/rhV9/Smx4Y0V/xz8n79RS5fcb7+CultO8kVh2VZlgAAgLGcmR4AAACkRqwBADAc\nsQYAwHDEGgAAwxFrAAAMR6wBADDcHcX66tWrKi8vV19fny5duqTa2lrV1dVp48aNyXM6Ojq0bNky\nVVdX69ixY3bNCwDAlJM21iMjI2ppadH06dMlSVu2bFE4HNb+/fs1Ojqqzs5ODQwMqLW1Ve3t7dq3\nb5927NihRCJh+/AAAEwFaWO9bds21dTUaNasWbIsSxcvXlRJSYkkqaysTCdPnlR3d7eKi4vlcrnk\n9XoVCATU09Nj+/AAAEwFKWN98OBBffOb31Rpaak+v9DZ6Oho8va8vDxFo1HFYjH5fL7k8dzcXEUi\nEZtGBgBganGluvHgwYNyOBw6ceKEenp6tGbNGl2/fj15eywWU35+vrxer6LR6G3H07EsSw6H42uM\nDwDA5Jcy1vv370/+e8WKFdq4caO2b9+uM2fO6LHHHtPx48e1ePFiFRUVaefOnYrH4xoeHlZvb68K\nCwvTfnGHw6H+fl6B28nv97HjCcCe7ceO7ceO7ef3+9Kf9BVSxvqrrFmzRuvWrVMikVBBQYGqqqrk\ncDgUCoVUW1sry7IUDofl8XjGNBAAAPgyR6b/6hbP4uzFM+WJwZ7tx47tx47tN9ZX1lwUBQAAwxFr\nAAAMR6wBADAcsQYAwHDEGgAAwxFrAAAMR6wBADAcsQYAwHDEGgAAwxFrAAAMR6wBADAcsQYAwHDE\nGgAAwxFrAAAMR6wBADAcsQYAwHDEGgAAwxFrAAAMR6wBADAcsQYAwHDEGgAAwxFrAAAMR6wBADAc\nsQYAwHDEGgAAwxFrAAAMR6wBADAcsQYAwHCuTH7x3/+vP+rGjZuZHOGu+LxePV763zI9BgBgislo\nrH/b/r817RsFmRzhrky/+QGxBgBMuIzGOsflkcs9PZMj3BWXy5PpEQAAU1DaWI+Ojqq5uVl9fX1y\nOp3auHGjEomEXnnlFQUCAUlSTU2NlixZoo6ODrW3t8vtdquhoUHl5eU2jw8AwOSXNtZdXV1yOBxq\na2vT6dOn9eabb+oHP/iBVq1apZUrVybPGxgYUGtrqw4dOqShoSHV1NSotLRUbrfbzvkBAJj00sa6\noqJCTzzxhCTp8uXLuueee3ThwgX19fWps7NTgUBATU1N6u7uVnFxsVwul7xerwKBgHp6erRgwQLb\nHwQAAJPZHX3P2ul0qrGxUZ2dnfrtb3+rK1eu6Pnnn9e8efO0d+9e7dq1S3PnzpXP50t+Tm5uriKR\niG2DZ4LLnSO/35f+RMNk48zZiD3bjx3bjx2b6Y5/wGzr1q26evWqgsGgDhw4oFmzZkn6z1femzdv\n1qJFixSNRpPnx2Ix5efnj//EGTSSuKX+/ux6AuL3+7Ju5mzEnu3Hju3Hju031idDaS+KcvjwYb39\n9tuSpGnTpsnhcOjHP/6xuru7JUmnTp3S/PnzVVRUpLNnzyoejysSiai3t1eFhYVjGgoAAHwh7Svr\nJ598Uk1NTaqrq9PIyIjWrl2r++67T5s2bZLb7Zbf79emTZuUl5enUCik2tpaWZalcDgsj4dfdQIA\n4OtKG+sZM2borbfeuu14W1vbbceCwaCCweD4TAYAACRxbXAAAIxHrAEAMByxBgDAcMQaAADDEWsA\nAAxHrAEAMByxBgDAcMQaAADDEWsAAAxHrAEAMByxBgDAcMQaAADDEWsAAAxHrAEAMByxBgDAcMQa\nAADDEWsAAAxHrAEAMByxBgDAcMQaAADDEWsAAAxHrAEAMByxBgDAcMQaAADDEWsAAAxHrAEAMByx\nBgDAcMQaAADDEWsAAAxHrAEAMJwr3Qmjo6Nqbm5WX1+fnE6nNm7cKI/Ho8bGRjmdThUWFqqlpUWS\n1NHRofb2drndbjU0NKi8vNzu+QEAmPTSxrqrq0sOh0NtbW06ffq03nzzTVmWpXA4rJKSErW0tKiz\ns1MLFy5Ua2urDh06pKGhIdXU1Ki0tFRut3siHgcAAJNW2lhXVFToiSeekCT961//0j333KOTJ0+q\npKREklRWVqYTJ07I6XSquLhYLpdLXq9XgUBAPT09WrBggb2PAACASe6OvmftdDrV2NiozZs3a+nS\npbIsK3lbXl6eotGoYrGYfD5f8nhubq4ikcj4TwwAwBST9pX157Zu3aqrV69q+fLlGh4eTh6PxWLK\nz8+X1+tVNBq97fhk4nLnyO/3pT/RMNk4czZiz/Zjx/Zjx2ZKG+vDhw/rypUrevnllzVt2jQ5nU4t\nWLBAp0+f1qJFi3T8+HEtXrxYRUVF2rlzp+LxuIaHh9Xb26vCwsKJeAwTZiRxS/392fVugd/vy7qZ\nsxF7th87th87tt9YnwyljfWTTz6ppqYm1dXVaWRkRM3Nzfr2t7+t5uZmJRIJFRQUqKqqSg6HQ6FQ\nSLW1tckfQPN4PGMaCgAAfCFtrGfMmKG33nrrtuOtra23HQsGgwoGg+MzGQAAkMRFUQAAMB6xBgDA\ncMQaAADDEWsAAAxHrAEAMByxBgDAcMQaAADDEWsAAAxHrAEAMByxBgDAcMQaAADDEWsAAAxHrAEA\nMByxBgDAcMQaAADDEWsAAAxHrAEAMByxBgDAcMQaAADDEWsAAAxHrAEAMByxBgDAcMQaAADDEWsA\nAAxHrAEAMByxBgDAcMQaAADDEWsAAAxHrAEAMByxBgDAcK5UN46MjOj111/X5cuXlUgk1NDQoPvu\nu0+vvPKKAoGAJKmmpkZLlixRR0eH2tvb5Xa71dDQoPLy8gkYHwCAyS9lrI8cOaJ7771X27dv140b\nN/TMM8/oRz/6kVatWqWVK1cmzxsYGFBra6sOHTqkoaEh1dTUqLS0VG632+75AQCY9FLGesmSJaqq\nqpIkjY6OyuVy6cKFC+rt7VVnZ6cCgYCamprU3d2t4uJiuVwueb1eBQIB9fT0aMGCBRPyIAAAmMxS\nxnrGjBmSpGg0qtWrV+snP/mJ4vG4gsGg5s2bp71792rXrl2aO3eufD5f8vNyc3MViUTsnRwAgCki\nZawl6dNPP9Vrr72muro6PfXUU4pEIskwV1RUaPPmzVq0aJGi0Wjyc2KxmPLz8+2bOkNc7hz5/b70\nJxomG2fORuzZfuzYfuzYTCljPTAwoPr6eq1fv16LFy+WJNXX12vdunUqKirSqVOnNH/+fBUVFWnn\nzp2Kx+MaHh5Wb2+vCgsLJ+QBTKSRxC3192fXOwZ+vy/rZs5G7Nl+7Nh+7Nh+Y30ylDLWe/fu1eDg\noPbs2aPdu3fL4XCoqalJv/rVr+R2u+X3+7Vp0ybl5eUpFAqptrZWlmUpHA7L4/GMaSAAAPBlDsuy\nrEx98cqVv9H0b2bPK/DpsX9ozy//e6bHuCs8U54Y7Nl+7Nh+7Nh+Y31lzUVRAAAwHLEGAMBwxBoA\nAMMRawAADEesAQAwHLEGAMBwxBoAAMMRawAADEesAQAwHLEGAMBwxBoAAMMRawAADEesAQAwHLEG\nAMBwxBoAAMMRawAADEesAQAwHLEGAMBwxBoAAMMRawAADEesAQAwHLEGAMBwxBoAAMMRawAADOfK\n9AAAAIzFrVu39PHHvZke4674/Y+O6fOINQAgK338ca9W//qIcu+ZlelR7sjNG/+hD94n1gCAKSb3\nnlny3nt/psewHd+zBgDAcMQaAADDEWsAAAxHrAEAMFzKHzAbGRnR66+/rsuXLyuRSKihoUEPPfSQ\nGhsb5XQ6VVhYqJaWFklSR0eH2tvb5Xa71dDQoPLy8omYHwCASS9lrI8cOaJ7771X27dv1+DgoJ5+\n+mk9/PDDCofDKikpUUtLizo7O7Vw4UK1trbq0KFDGhoaUk1NjUpLS+V2uyfqcQAAMGmljPWSJUtU\nVVUl6T9/+TwnJ0cXL15USUmJJKmsrEwnTpyQ0+lUcXGxXC6XvF6vAoGAenp6tGDBAvsfAQAAk1zK\nWM+YMUOSFI1GtXr1av30pz/Vtm3bkrfn5eUpGo0qFovJ5/Mlj+fm5ioSidg0cua43Dny+33pTzRM\nNs6cjdiz/dix/bJpx9evezM9woRJe1GUTz/9VK+99prq6ur01FNP6de//nXytlgspvz8fHm9XkWj\n0duOTzYjiVvq78+uJyF+vy/rZs5G7Nl+7Nh+2bbja9ei6U+aJFL+NPjAwIDq6+v185//XM8++6wk\nae7cuTpz5owk6fjx4youLlZRUZHOnj2reDyuSCSi3t5eFRYW2j89AABTQMpX1nv37tXg4KD27Nmj\n3bt3y+FwaO3atdq8ebMSiYQKCgpUVVUlh8OhUCik2tpaWZalcDgsj8czUY8BAIBJLWWs165dq7Vr\n1952vLW19bZjwWBQwWBw/CYDAACSuCgKAADGI9YAABiOWAMAYDhiDQCA4Yg1AACGI9YAABiOWAMA\nYDhiDQCA4Yg1AACGI9YAABiOWAMAYDhiDQCA4Yg1AACGI9YAABiOWAMAYDhiDQCA4Yg1AACGI9YA\nABiOWAMAYDhiDQCA4Yg1AACGI9YAABiOWAMAYDhiDQCA4Yg1AACGI9YAABiOWAMAYDhiDQCA4Yg1\nAACGI9YAABjujmJ9/vx5hUIhSdLf//53lZWVacWKFVqxYoX+8Ic/SJI6Ojq0bNkyVVdX69ixY7YN\nDADAVONKd8K+fft0+PBh5eXlSZI+/PBDrVq1SitXrkyeMzAwoNbWVh06dEhDQ0OqqalRaWmp3G63\nbYMDADBVpH1lPWfOHO3evTv58YULF3Ts2DHV1dWpublZsVhM3d3dKi4ulsvlktfrVSAQUE9Pj62D\nAwAwVaSNdWVlpXJycpIfP/LII/rFL36h/fv3a/bs2dq1a5ei0ah8Pl/ynNzcXEUiEXsmBgBgikn7\nNvh/VVFRkQxzRUWFNm/erEWLFikajSbPicViys/PH78pDeFy58jv96U/0TDZOHM2Ys/2Y8f2y6Yd\nX7/uzfQIE+auY11fX69169apqKhIp06d0vz581VUVKSdO3cqHo9reHhYvb29KiwstGPejBpJ3FJ/\nf3a9Y+D3+7Ju5mzEnu3Hju2XbTu+di2a/qRJ4q5jvWHDBv3yl7+U2+2W3+/Xpk2blJeXp1AopNra\nWlmWpXA4LI/HY8e8AABMOXcU6/vvv18HDhyQJM2bN09tbW23nRMMBhUMBsd3OgAAwEVRAAAwHbEG\nAMBwxBoAAMMRawAADEesAQAwHLEGAMBwxBoAAMMRawAADEesAQAwHLEGAMBwxBoAAMMRawAADEes\nAQAwHLEGAMBwxBoAAMMRawAADEesAQAwHLEGAMBwxBoAAMMRawAADEesAQAwHLEGAMBwxBoAAMMR\nawAADEesAQAwHLEGAMBwxBoAAMMRawAADEesAQAwHLEGAMBwdxTr8+fPKxQKSZIuXbqk2tpa1dXV\naePGjclzOjo6tGzZMlVXV+vYsWO2DAsAwFSUNtb79u1Tc3OzEomEJGnLli0Kh8Pav3+/RkdH1dnZ\nqYGBAbW2tqq9vV379u3Tjh07kucDAICvJ22s58yZo927dyc/vnDhgkpKSiRJZWVlOnnypLq7u1Vc\nXCyXyyWv16tAIKCenh77pgYAYApJG+vKykrl5OQkP7YsK/nvvLw8RaNRxWIx+Xy+5PHc3FxFIpFx\nHhUAgKnJdbef4HR+0fdYLKb8/Hx5vV5Fo9Hbjk82LneO/H5f+hMNk40zZyP2bD92bL9s2vH1695M\njzBh7jrW8+bN05kzZ/TYY4/p+PHjWrx4sYqKirRz507F43ENDw+rt7dXhYWFdsybUSOJW+rvz653\nDPx+X9bNnI3Ys/3Ysf2ybcfXrkXTnzRJ3HWs16xZo3Xr1imRSKigoEBVVVVyOBwKhUKqra2VZVkK\nh8PyeDx2zAsAwJRzR7G+//77deDAAUlSIBBQa2vrbecEg0EFg8HxnQ4AAHBRFAAATEesAQAwHLEG\nAMBwxBoAAMMRawAADEesAQAwHLEGAMBwxBoAAMMRawAADEesAQAwHLEGAMBwxBoAAMMRawAADEes\nAQAwHLEGAMBwxBoAAMMRawAADEesAQAwHLEGAMBwxBoAAMMRawAADEesAQAwHLEGAMBwxBoAAMMR\nawAADEesAQAwHLEGAMBwxBoAAMMRawAADEesAQAwHLEGAMBwrrF+4nPPPSev1ytJ+ta3vqWGhgY1\nNjbK6XSqsLBQLS0t4zYkAABT2ZhiHY/HJUnvvvtu8tirr76qcDiskpIStbS0qLOzUxUVFeMzJQAA\nU9iY3gb/xz/+oZs3b6q+vl4rV67U+fPndfHiRZWUlEiSysrKdOrUqXEdFACAqWpMr6ynT5+u+vp6\nBYNBffzxx3rppZdkWVby9ry8PEUikXEb0hQud478fl+mx7hr2ThzNmLP9mPH9sumHV+/7s30CBNm\nTLEOBAKaM2dO8t8zZ87UxYsXk7fHYjHl5+ePz4QGGUncUn9/dj0J8ft9WTdzNmLP9mPH9su2HV+7\nFs30CBNmTG+Dv//++9q6dask6cqVK4pGoyotLdXp06clScePH1dxcfH4TQkAwBQ2plfWy5cvV1NT\nk2pra+V0OrV161bNnDlTzc3NSiQSKigoUFVV1XjPCgDAlDSmWLvdbv3mN7+57Xhra+vXHggAAHwZ\nF0UBAMBwxBoAAMMRawAADEesAQAwHLEGAMBwxBoAAMMRawAADEesAQAwHLEGAMBwxBoAAMMRawAA\nDEesAQAwHLEGAMBwxBoAAMMRawAADEesAQAwHLEGAMBwxBoAAMMRawAADEesAQAwHLEGAMBwxBoA\nAMMRawAADEesAQAwHLEGAMBwxBoAAMMRawAADEesAQAwHLEGAMBwxBoAAMO5xvPOLMvShg0b1NPT\nI4/HozfeeEOzZ88ezy8BAMCUM66vrDs7OxWPx3XgwAH97Gc/05YtW8bz7gEAmJLGNdZnz57V448/\nLkl65JFH9OGHH47n3QMAMCWN69vg0WhUPp/vizt3uTQ6Oiqn86ufE1jRTzSqofEcwVaJW9f00Uf/\nJ9Nj3JXr1726di2a6TEmPfZsP3Zsv2zb8aVLn+jmjf/I9Bh37OvMOq6x9nq9isViyY9ThVqSOv/n\n/xjPLw8AmEIWL35Uzz//bKbHmBDj+jb4o48+qr/85S+SpHPnzuk73/nOeN49AABTksOyLGu87uz/\n/WlwSdqyZYsefPDB8bp7AACmpHGNNQAAGH9cFAUAAMMRawAADEesAQAwHLEGAMBwtsfasiy1tLSo\nurpaK1as0D//+c8v3d7V1aXly5erurpa7733nt3jTFrp9nz06FE9//zzqq2t1YYNGzIzZJZLt+PP\nrV+/Xm+++eYETzc5pNtxd3e3XnzxRb344otavXq14vF4hibNbun2fOTIET333HMKBoNqa2vL0JST\nw/nz5xUKhW47ftfts2z25z//2WpsbLQsy7LOnTtnvfrqq8nbEomEVVlZaUUiESsej1vLli2zrl69\navdIk1KqPQ8NDVmVlZXW8PCwZVmWFQ6Hra6urozMmc1S7fhzbW1t1gsvvGDt2LFjosebFNLt+Omn\nn7YuXbpkWZZlvffee1ZfX99EjzgppNtzaWmpNTg4aMXjcauystIaHBzMxJhZ73e/+521dOlS64UX\nXvjS8bG0z/ZX1qmuF/7RRx9pzpw58nq9crvdKi4u1pkzZ+weaVJKtWePx6MDBw7I4/FIkkZGRjRt\n2rSMzJnN0l37/q9//av+9re/qbq6OhPjTQqpdtzX16eZM2fqnXfeUSgU0o0bNxQIBDI0aXZL93/5\n4Ycf1o0bNzQ8PCxJcjgcEz7jZDBnzhzt3r37tuNjaZ/tsf7/XS/8q27Ly8tTJBKxe6RJKdWeHQ6H\nvvGNb0iSWltb9dlnn+l73/teRubMZql23N/fr127dmn9+vWyuHTBmKXa8fXr13Xu3DmFQiG98847\nOnnypD744INMjZrVUu1ZkgoLC7Vs2TL98Ic/VHl5ubxebybGzHqVlZXKycm57fhY2md7rFNdL9zr\n9Soa/eKi8bFYTPn5+XaPNCmluy67ZVnatm2bTp06pV27dmVixKyXasd//OMf9e9//1svvfSS3n77\nbR09elS///3vMzVq1kq145kzZ+qBBx7Qgw8+KJfLpccff5y/7DdGqfbc09OjY8eOqaurS11dXbp6\n9ar+9Kc/ZWrUSWks7bM91qmuF15QUKBPPvlEg4ODisfjOnPmjBYuXGj3SJNSuuuyr1u3TolEQnv2\n7Em+HY67k2rHoVBI77//vt599129/PLLWrp0qZ555plMjZq1Uu149uzZunnzZvKHoc6ePauHHnoo\nI3Nmu1R79vl8mjFjhjweT/JducHBwUyNOin813fbxtK+cf2rW1+lsrJSJ06cSH4fb8uWLTp69Kg+\n++wzBYNBNTU1adWqVbIsS8FgULNmzbJ7pEkp1Z7nz5+vgwcPqri4WKFQSA6HQytWrFBFRUWGp84u\n6f4v4+tLt+M33nhD4XBYkvTd735X3//+9zM5btZKt+fPf3PE4/HogQce0LPPTo2/bGWXz7/n/3Xa\nx7XBAQAwHBdFAQDAcMQaAADDEWsAAAxHrAEAMByxBgDAcMQaAADDEWsAAAz3fwGqYbDDUBaLGQAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11682e650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['diagnosis'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Wybieramy cechy\n",
    "prediction_var = ['texture_mean','perimeter_mean','smoothness_mean','compactness_mean','symmetry_mean']\n",
    "train, test = train_test_split(data, test_size = 0.3)# in this our main data is splitted into train and test\n",
    "train_X = train[prediction_var][0:100]\n",
    "train_y=train.diagnosis[0:100]\n",
    "test_X= test[prediction_var] \n",
    "test_y =test.diagnosis  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912280701754\n",
      "0.910714285714\n",
      "0.83606557377\n",
      "0.189882234815\n"
     ]
    }
   ],
   "source": [
    "# Regresja logistyczna\n",
    "model = LogisticRegression(C=50)\n",
    "model.fit(train_X,train_y)\n",
    "pred = model.predict(test_X)\n",
    "print metrics.accuracy_score(pred, test_y)\n",
    "print metrics.precision_score(pred, test_y)\n",
    "print metrics.recall_score(pred, test_y)\n",
    "print metrics.log_loss(test_y, model.predict_proba(test_X)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1 [3 pkt]\n",
    "\n",
    "1. Powyższy model ma istotnie wyższy recall niż precision. \n",
    "\n",
    "Zdefiniujmy jako model probabilistyczny model, który zwraca p($\\hat{y}$ | y). Obiekt LogisticRegression zwraca tą wartość funkcją ``predict_proba``\n",
    "\n",
    "1. Każdy model probabilistyczny można użyć do stworzenia klasyfikora, która może mieć precision 100% lub recall 100% trywialnie, jak? \n",
    "\n",
    "2. Krzywa precision/recall jest obliczana licząc precision oraz recall modelu probabilistycznego dla różnych wartości precision. Zarysuj wykres precision/recall dla modelu powyżej.\n",
    "\n",
    "Powinno wyjść:\n",
    "\n",
    "<img src=\"figures/L7/prec_recall.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2 [3 pkt]\n",
    "\n",
    "Założmy, że $C_{FP}$ = 1 i $C_{FN}$ = 10, co odpowiada sytuacji w której nie przejmujemy się postawieniem fałszywej pozytywnej diagnozy.\n",
    "\n",
    "Według http://web.cs.iastate.edu/~honavar/elkan.pdf wystarczy w takim wypadku dodać przykładom odpowiednią wage.\n",
    "\n",
    "a) Przetestuj pare wag klasy negatywnej przez podanie argumentu class_weight do LogisticRegression. Dla każdej wartości wagi narysuj dokładność (accuracy) oraz wynik metryki FN_aversive. Powinno wyjść:\n",
    "\n",
    "<img src=\"figures/L7/fn_aversive.png\">\n",
    "\n",
    "b) Równoważnym sposobem tworzenia \"cost-sensitive\" klasyfikatora z modelu probabilistycznego jest zmiana progu (patrz Zadanie 1). Znajdź taki próg, aby wynik klasyfikatora z tym progiem był równoważny argumentowi class_weight, który daje w punkcie a) najlepszy wynik.\n",
    "\n",
    "Podpowiedź: Jeśli 2 sprawia problem, przejrzyj załączoną publikację"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FN_aversive(y_true, y_pred):\n",
    "    FN = sum((y_true == 1) * (y_pred != y_true))\n",
    "    FP = sum((y_true == 0) * (y_pred != y_true))\n",
    "    return 10 * FN + FP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metryki c.d. (model probabilistyczny)\n",
    "\n",
    "Metryki wcześniej wprowadzone zakładają na wejściu klasyfikator, albo model probabilistyczny z dobranym na twardo thresholdem. Trochę bardziej skomplikowanym modelem może być model probabilistyczny, który zwraca jedynie prawdopodobieństwo\n",
    "\n",
    "## Entropia krzyżowa/log loss (dla klasyfikacji binarnej)\n",
    "\n",
    "Entropia krzyżowa, inaczej log loss jest niczym innym jak dobrze nam znanym log likelihood modelu zastosowanym do modeli probabilistycznych (zwracających prawdopodobieństwo):\n",
    "\n",
    "$$ LL(\\hat y, y) = CE(\\hat y, y) = \\sum_{i=1}^{N} y \\log\\hat(y) $$.\n",
    "\n",
    "Entropia krzyżowa może być też bezpośrednio optymalizowana, w odróżnieniu od metryk typu accuracy, precision czy recall.\n",
    "\n",
    "Warto wspomnieć, że niektóre modele mają dobre accuracy, ale słaby log loss (np. Naive Bayes).\n",
    "\n",
    "## ROC\n",
    "\n",
    "Krzywa ROC tworzona jest podobnie jak krzywa precision recall, tylko tym razem dla każdego progu liczymy true positive rate (p oraz false positive rate.\n",
    "\n",
    "<img src=\"figures/L7/roc_curve.png\">\n",
    "\n",
    "Czasami chcemy opisać krzywą ROC jedną liczbą, z oczywistych względów musimy coś \"oszukać\" (tj. stracić jakąś informację). Popularny sposób to pole powierzni pod krzywą ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes vs Regresja Logistyczna \n",
    "\n",
    "Ref: https://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wyprowadzenie\n",
    "\n",
    "[Wyprowadzić na zajęciach]\n",
    "\n",
    "**Wyprowadzenie zaczynamy od zdefiniowania procesu generowania danych**\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "Zakładamy niezależność cech\n",
    "\n",
    "$$ p(X | Y) = \\prod_i P(X_i | Y) $$\n",
    "\n",
    "### Regresja logistyczna (binarna)\n",
    "\n",
    "Zdefiniujmy ``odds`` jako\n",
    "\n",
    "$$ o = \\frac{p(Y=1 | x)}{p(Y=0| x)} $$\n",
    "\n",
    "Wtedy regresja logistyczna definiuje:\n",
    "\n",
    "$$ \\log(o) = \\sum \\theta_i x_i $$\n",
    "\n",
    "**Teraz liczymy likelihood**\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "Naive Bayes to model generatywny (co jak dowiemy się niedługo ma wady). Użyjmy reguły Bayesa aby policzyć likelihood:\n",
    "\n",
    "$$ p(Y | X) = P(X | Y) P(Y)  = ( \\prod_i P(X_i | Y)) P(Y) $$\n",
    "\n",
    "### Regresja logistyczna\n",
    "\n",
    "Przekształcając $$ \\log(o) = \\sum \\theta_i x_i $$ otrzymujemy *bezpośrednio*, że $$ p(y | x) = \\mbox{sigmoid}(\\sum \\theta_i x_i) $$, gdzie $sigmoid(a) = \\frac{1}{1 + \\exp(-a)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Różnice pomiędzy Naive Bayes a regresją logistyczną\n",
    "\n",
    "### Niezależność cech\n",
    "\n",
    "Naive Bayes zakłada niezależność cech (brak korekty liniowych zależności). Mówiąc inaczej możemy \"wrzucić\" do regresji logistycznej skorelowane cechy i się nic nie stanie. W przypadku modelu Naive Bayes nazywamy ten problem \"double counting\".\n",
    "\n",
    "\n",
    "### Model dyskryminatywny vs generatywny\n",
    "\n",
    "Przez model generatywny rozumiem model, który optymalizuje łączne prawdopodobieństwo p(x, y).\n",
    "\n",
    "**Obserwacja 1.** Modelowanie p(x | y) lub p(x) nie jest bezpośrednio niezbędne do modelowania p(y | x). \n",
    "\n",
    "Obserwacja 1. mówi nam, że model generatywny wykonuje \"dodatkową\" pracę. W związku z tym czemu modele generatywne są aktywnie wykorzystywane w praktyce? Jest to po prostu kolejny sposób regularyzacji! Modelując p(x | y) można (niezbyt ściśle) powiedzieć, że modelujemy sposób w jaki funkcjonuje świat. Zainteresowanych odsyłamy do https://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf oraz [TODO]\n",
    "\n",
    "Naive Bayes to *model generatywny*, a *regresja logistyczna* to model dyskryminatywny. W związku z tym należy oczekiwać, że w granicy danych regresja logistyczna będzie osiągać lepsze wyniki, ale może być różnie w przypadku małej ilości danych\n",
    "\n",
    "<img src=\"figures/L7/ng_plot.png\">\n",
    "\n",
    "(Obrazek za https://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf).\n",
    "\n",
    "### Log loss\n",
    "\n",
    "Naive Bayes daje zbyt optymistyczne prawdopodobieństwa. Jest dobry w accuracy, ale zły w log lossie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918128654971\n",
      "0.818181818182\n",
      "0.964285714286\n",
      "0.203777398379\n"
     ]
    }
   ],
   "source": [
    "# Przykład słabego log lossu modelu Naive Bayes\n",
    "model = GaussianNB()\n",
    "model.fit(train_X,train_y)\n",
    "pred = model.predict(test_X)\n",
    "print metrics.accuracy_score(test_y, pred,)\n",
    "print metrics.precision_score(test_y, pred)\n",
    "print metrics.recall_score(test_y, pred)\n",
    "# Regresja logistyczna osiąga 0.26\n",
    "print metrics.log_loss(test_y, model.predict_proba(test_X)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 [3 pkt]\n",
    "\n",
    "Naive Bayes jest często stosowany do problemów klasyfikacyjnych na tekście. W tym zadaniu zajmiemy się klasyfikacją SPAMU. Na wejściu zadany jest test wiadomości e-mail, etykietą jest 0 (prawdziwa wiadomość, \"HAM\") lub 1 (SPAM). \n",
    "\n",
    "Podstawowym problemem jest sposób reprezentacji tekstu. Podobnie jak w przypadku rozważanych funkcji bazowych na wcześniejszych zajęciach, modele wymagają stałowymiarowego wektoru. Proszę użyć klasy CountVectorizer z sklearn w celu przekształcenia wiadomości do reprezentacji wektorowej.\n",
    "\n",
    "1. Zastosuj transformację tekstu do reprezentacji bag of words\n",
    "2. Naucz model Naive Bayes (MultinomialNB) przewidywać SPAM\n",
    "3. Pokaż problem \"double counting\" w modelu Naive Bayes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Załadowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages = pd.read_csv('data/L7/SMSSpamCollection/SMSSpamCollection', sep='\\t', quoting=csv.QUOTE_NONE,\n",
    "                           names=[\"label\", \"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksploracja danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">ham</th>\n",
       "      <th>count</th>\n",
       "      <td>4827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">spam</th>\n",
       "      <th>count</th>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        message\n",
       "label                                                          \n",
       "ham   count                                                4827\n",
       "      unique                                               4518\n",
       "      top                                Sorry, I'll call later\n",
       "      freq                                                   30\n",
       "spam  count                                                 747\n",
       "      unique                                                653\n",
       "      top     Please call our customer service representativ...\n",
       "      freq                                                    4"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                            message  length\n",
      "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
      "1   ham                      Ok lar... Joking wif u oni...      29\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
      "3   ham  U dun say so early hor... U c already then say...      49\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...      61\n"
     ]
    }
   ],
   "source": [
    "messages['length'] = messages['message'].map(lambda text: len(text))\n",
    "print messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11b2ebd10>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAECCAYAAADZ+iH+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7Y5YM5pNEqIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b2ddb90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages.length.plot(bins=20, kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x11adde9d0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x11aeff190>], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEQCAYAAACugzM1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHuJJREFUeJzt3X+QHPV55/H3SkgCsaOF1Y2UWARkMH7EhYgf9vHLsiR8\nyIDimOOqglOUyxAHceEIkUmBDeLgChtZnGWIjZ2QQpYPDBfjQAVbtg4IBBKvwtnmNyiWHwmUlQjG\nsGhX+wMJJO3u/dE9q9Gy6u3pmZ7u2fm8qra009Mzz3c0+/TT/f1+u7tleHgYERGRg5mUdQNERCTf\nVChERCSSCoWIiERSoRARkUgqFCIiEkmFQkREIqlQ5JCZLTKzl7Nuh4gIqFDkmU5wEZFcOCTrBshB\nFczs+8A8YBqwDHgL+CvgcOADwAvAZ9x9j5ntBv4S+BRQAL4I/CHwe8DrwB+4++66fwqRCpnZ4cD/\nBj4EDAHPAd8H/hfB3/KxwC7gUnd3Mzse5UWqdESRX3OA29z9FOAu4GbgMuBud/8YcDxBwvx+uP40\n4HV3nw/cCawB/tzdTwCOAC6oc/tFkroQaHX3U4HTCI6ujwVOAVa7+0nA3cB94frLUF6kSoUiv151\n92fC318Aiu7+JeBtM7uW4I/+t4HWstf8fem1wMvu/pvw8b8B7XVos0gtbAB+18yeBK4Dvgm8Arzo\n7k+F63wXOMXMjgSUFylT11N+7S37fRiYZGb3A5OBvwN+AhwNtJSt995BXi/SMNy908w+BCwGPgE8\nDlwF7CtbrbSTOwjcHz5WXqRERxSN5ZPAl939AYJEOJ2gcIhMGGb2pwRdSY+5+/XAo8CfASeb2Ynh\napcDG9y9D+VF6nRE0TiGgRXAD81sB8Fg3j8RDPiVno96rUij+B6wyMx+CQwA24FvEIw9rDSzDwJv\nAp8L178e5UWqWnSZcRHJOzNbBHwrHJSWOot1RGFmpwO3uvvZZlYkmDlwBMHh3efc/d/MbBnB4eBe\nYKW7rzezQwlmJswC+oBL3H1HGh9EJEtJcyS7FovEN+4YRTiTYA3BNDOArwH3ufti4EZgnpnNJhhs\nOhM4D1hlZlOAK4CX3H0hcG+4vsiEUmWOSAzu/s86mshOnMHsVwjmNZd8DDjKzB4DLiboDzyNYGBp\nXzi4tAU4CVgAPBK+7mHgnBq1WyRPkuaINnzSEMYtFO7+EAdOS5sLdLv7EuA1gnnOM4DesnUGgDaC\nMyFLy/vD9cY1HAyc6Ec/tf5JRZU5Ekm5oJ+UfiqSZNbTDuDH4e8/BlYCT3NgESgAPQTjEoWyZTvj\nBGhpaaGrqz9B06pTLBYUd4LHrZO4OTJuPigXFDetuJVIch5FB7A0/H0hsJEgCRaY2VQzayO4PtFG\n4KmydZeGrxWZ6CrJEZHcS1IorgEuMbMNwLnAV939TeAOglPvHwdWuPsegtPpTzSzDoLrFN1cm2aL\n5FolOSKSe3k9j2K42Q4DFbcucVvGXyt3lAuKm0bcinJBl/AQEZFIKhQiIhJJhUJERCKpUIiISCQV\nChERiaRCISIikVQoREQkkgqFiIhEUqEQEZFIKhQiIhJJhUJERCKpUIiISCQVChERiaRCISIikVQo\nREQkUpJbodbN4OAgnZ1bAZg791gmT56ccYtERJpPro8oOju3snz1OpavXjdSMEREpL5yfUQBML1t\nVtZNEBFpark+ohARkezFOqIws9OBW9397LJlFwN/5u5nhY+XAZcDe4GV7r7ezA4F7gNmAX3AJe6+\no8afQSRzSXMkk8aKVGjcIwozuxZYA0wrW3YK8Pmyx7OBq4AzgfOAVWY2BbgCeMndFwL3AjfWtPUi\nOVBljkjODA4O8uqrW0Z+BgcHs25S5uJ0Pb0CXFh6YGYzgVuA5WXrnAZscPd97t4HbAFOAhYAj4Tr\nPAycU4tGi+RM0hyZX9dWSiylSTTX3/UzTaQJjdv15O4PmdkxAGY2CfgO8BfAe2WrzQB6yx4PAG1A\noWx5f7heLMVigZ6e1pHH7e2tFIuFuC9PrB4xFDe7uGmoMkfG1WzfUdZxe3pamd42i9Yj5wDpb3sa\nIRcqnfV0KvAh4E7gMOAEM7sdeJIDi0AB6CEYlyiULdsZN1BXVz/d3QMjj7u7B+jq6q+wuZUpFgup\nx1DcbOPWQSU5Eisfmu07yjpu+Xan9DitNjVKLlRSKFrc/Rng9wDCPajvu/tfhP2vt5jZVILkmAds\nBJ4ClgLPhP92VNQ6kcaSJEdEcq+S6bHDB3vC3d8E7gA2AI8DK9x9D8Fe1Ylm1gFcBtxcRVtF8i5J\njojkXqwjCnffBpwVtczd1wJrR62zG7io+maK5FvSHBFpBDrhTkREIqlQiIhIJBUKERGJpEIhIiKR\nVChERCSSCoWIiERSoRARkUgqFCIiEkmFQkREIqlQiIhIJBUKERGJpEIhIiKRVChERCSSCoWIiERS\noRARkUgqFCIiEkmFQkREIqlQiIhIJBUKERGJFOue2WZ2OnCru59tZicT3CR+H/Ae8Dl37zKzZcDl\nwF5gpbuvN7NDgfuAWUAfcIm770jjg4hkKWmOZNdikfjGPaIws2uBNcC0cNE3gCvd/RPAQ8CXzGw2\ncBVwJnAesMrMpgBXAC+5+0LgXuDG2n8EkWxVmSMiuRen6+kV4MKyx59x95fD3w8B3gVOAza4+z53\n7wO2ACcBC4BHwnUfBs6pSatF8iVpjsyvbzNFkhm368ndHzKzY8oevwlgZmcBVwILCfaQesteNgC0\nAYWy5f3AjLgNKxYL9PS0jjxub2+lWCzEfXli9YihuNnFTUOVOTKuZvuOso5bvt2B9Lc9jZALscYo\nRjOzzwDXA0vdfYeZ9XFgESgAPQTjEoWyZTvjxujq6qe7e2DkcXf3AF1d/UmaG1uxWEg9huJmG7de\nYuZIrHxotu8o67jl253S47Ta1Ci5UHGhMLPPEgzILXb30h/6L4BbzGwqcBgwD9gIPAUsBZ4J/+2o\nNJ5Io6kwR0Ryr6JCYWaTgG8C24CHzGwY+Gd3v9nM7gA2AC3ACnffY2Z3AveYWQfB7I+La9t8kXyp\nNEcybKpIbLEKhbtvA84KH848yDprgbWjlu0GLqqmgSKNIGmOiDQCnXAnIiKRVChERCSSCoWIiERS\noRARkUgqFCIiEkmFQkREIiU6M1tEZKIZHByks3Mr27dvy7opuaNCISICdHZuZfnqdezu38HMo07I\nujm5okIhIhKa3jYLGM66GbmjMQoREYmkQiEiIpFUKEREJJIKhYiIRFKhEBGRSCoUIiISSYVCREQi\nqVCIiEgkFQoREYmkQiEiIpFiXcLDzE4HbnX3s83sOOBuYAjY6O5XhussAy4H9gIr3X29mR0K3AfM\nAvqAS9x9R+0/hki2kuZIVu0VqcS4RxRmdi2wBpgWLrodWOHui4BJZnaBmc0GrgLOBM4DVpnZFOAK\n4CV3XwjcC9yYwmcQyVSVOSKSe3G6nl4BLix7/BF37wh/fxhYApwGbHD3fe7eB2wBTgIWAI+UrXtO\nTVotki9Jc2R+fZspksy4XU/u/pCZHVO2qKXs935gBlAAesuWDwBto5aX1o2lWCzQ09M68ri9vZVi\nsRD35YnVI4biZhc3DVXmyLia7TvKKm57e+tBl6fZpkbIhSSXGR8q+70A7CQYf5gxanlPuLwwat1Y\nurr66e4eAGB4aIgXXvjXkcdz5x7L5MmTEzQ9WrFYoKurv+bvq7j5iVsncXMkVj4023eUVdzS9mW0\n7u6B1NrUKLmQZNbTc2a2MPz9fKADeBpYYGZTzawNmAdsBJ4ClobrLg3Xrdju/i5u+8GLXH/Xz1i+\neh2dnVuTvI1IvVSSIyK5l+SI4hpgTTgQtwl40N2HzewOYAPBYfcKd99jZncC95hZB/AecHHShk5v\nm0XrkXOSvlyknmLnSJaNFIkrVqFw923AWeHvW4DFY6yzFlg7atlu4KKqWymSc0lzRKQR6IQ7ERGJ\npEIhIiKRVChERCSSCoWIiERSoRARkUgqFCIiEkmFQkREIqlQiIhIJBUKERGJpEIhIiKRVChERCSS\nCoWIiERSoRARkUgqFCIiEkmFQkREIqlQiIhIJBUKERGJpEIhIiKRVChERCRSrHtmj2ZmhwD3AHOB\nfcAyYBC4GxgCNrr7leG6y4DLgb3ASndfX3WrRXKukhwRybukRxRLgcnu/jHgK8BXgduBFe6+CJhk\nZheY2WzgKuBM4DxglZlNqUG7RfIuVo5k2UCRuJIWis3AIWbWArQRHC2c6u4d4fMPA0uA04AN7r7P\n3fuALcD8Ktss0gji5Mg5WTVOpBKJup6AAeCDwK+AmcAfAB8ve74fmAEUgN5Rr2uLE6BYLNDT0zrm\nc+3trRSLhcpbHTNuFhR3womTI7FzIQvNFre9vf7bG2iMXEhaKK4GHnH3G8xsDvBPwNSy5wvATqCP\noGCMXj6urq5+ursHxnyuu3uArq7+BM2OViwWUnlfxc1P3DqKmyPjarbvKKu49d7elOI2Qi4k7Xrq\nZv+Rwk6CgvO8mS0Kl50PdABPAwvMbKqZtQHzgI0JY4o0krg5IpJ7SY8ovgF818x+CkwBrgOeBb4T\nDlZvAh5092EzuwPYALQQDOTtqUG7RfIuVo5k2D6R2BIVCnd/B/jMGE8tHmPdtcDaJHFEGlUlOSKS\ndzrhTkREIqlQiIhIJBUKERGJpEIhIiKRVChERCSSCoWIiERSoRARkUgqFCIiEkmFQkREIqlQiIhI\nJBUKERGJlPSigCIiDWlwcJDOzq0jj+fOPTbD1jQGFQoRaSqdnVtZvnod09tmsav3Lb557af5rd86\nNetm5ZoKhYg0nelts2g9ck7WzWgYGqMQEZFIKhQiIhJJhUJERCKpUIiISCQVChERiZR41pOZXQd8\nmuDG8X8N/BS4GxgCNrr7leF6y4DLgb3ASndfX2WbRRpC3BwRybtERxRmtgg4093PIrhZ/NHA7cAK\nd18ETDKzC8xsNnAVcCZwHrDKzKbUpOUiORY3RzJsogDDQ0Ns376NzZs3s337tqybk1tJjyjOBTaa\n2Q+BAvBF4DJ37wiffxj4JMGe0wZ33wf0mdkWYD7wbHXNFsm9ODmyBPhRRu0TYHd/F7f94G2mP/IG\nO/59EzOPOiHrJuVS0kLxHwj2kD4FHAus48Cjk35gBkGC9JYtHwDa4gQoFgv09LS+b/nw0BC9vV0j\nzx133HFMnjw5wUc4eNwsKO6EEydHYudCFiZq3NHbldLJd7t63xxz/fb21lTb1Ai5kLRQ7AA2hUcK\nm83sXeCosucLwE6gj6BgjF4+rq6ufrq7B963fHd/Fzfd9TbT214dOf3+uOOOT/gxDlQsFujq6q/J\neyluPuPWUdwcGVezfUdpxx1ruzLe+mm1qVFyIemspw0EYw6Y2QeAw4F/DPtlAc4HOoCngQVmNtXM\n2oB5wMaEMUeU9gCmt82q9q1E0hI3R0RyL9ERhbuvN7OPm9kvgBbgCqAT+E44WL0JeNDdh83sDoKk\naSEYyNtTm6aL5FfcHMmwiSKxJZ4e6+7XjbF48RjrrQXWJo0j0qji5ohI3umEOxERiaTLjIuIHETp\nPAsIbnBUyxmWjURHFCIiBxGcZ/Eiy1evO+CueM1GRxQiIhE0u1JHFCIiMg4VChERiaRCISIikVQo\nREQkkgqFiIhEUqEQEZFIKhQiIhJJhUJERCKpUIiISCQVChERiaRCISIikVQoREQkkgqFiIhEUqEQ\nEZFIDX2Z8fKbikBz31hERCQtVRUKM5sFPAOcAwwCdwNDwEZ3vzJcZxlwObAXWOnu66uJWS64qcjb\nTG97g129b/HNaz/NcccdX6u3F6lanBwRybvEXU9mdgjwN8CucNHtwAp3XwRMMrMLzGw2cBVwJnAe\nsMrMplTZ5gNMb5tF65FzdHMRyZ04OZJZ40QqUM0YxdeBO4FfAy3Aqe7eET73MLAEOA3Y4O773L0P\n2ALMryKmSCMZL0fOyaphzWJwcJBXX90y8jM4OJh1kxpSoq4nM7sUeMvdHzOzFeHi8qLTD8wACkBv\n2fIBoC1OjGKxQE9Pa0Xtam9vpVgsVPSaseJmQXEnlpg5EjsXsjAR4m7evJnlq9cxvW0Wu3rf4t5V\nF9PeXtl2paQW25exNEIuJB2j+GNgyMyWACcB3wOKZc8XgJ1AH0HBGL18XF1d/XR3D1TUqO7uAbq6\n+it6TblisVDV6xU3/3HrKG6OjKvZvqNaxu3uHhjpnh4eGuKFF/61qveq9f9Jo+RCokIR9rECYGZP\nAH8KrDazhe7+U+B84AngaWClmU0FDgPmARuTxBRpJBXkiKRgcHCQzs6tB8yKLE1+2d2/g5lHnZBh\n6xpPLafHXgOsCQerNwEPuvuwmd0BbCDoo13h7ntqGFOkkbwvRzJuz4TV2bmV5avXva8oBJNehrNr\nWIOqulC4+yfKHi4e4/m1wNpq44g0qvFyRNKholA7OjNbREQiqVCIiEgkFQoREYmkQiEiIpFUKERE\nJJIKhYiIRFKhEBGRSCoUIiISSYVCREQiqVCIiEikhr4VaiVKFwkr0W1TRUTiaZpCUbpIWOm69Lpt\nqohIPE1TKGD/bVNFRCS+CVMohoeG2L59W3irwxYmTw6GX9TFJCJSnQlTKPbflOQJDivMVBeTiEiN\nTJhCAfuvP68uJhGR2tH0WBERiaRCISIikSZU19NopQFu4ICbrIuISHyJCoWZHQJ8F5gLTAVWAr8E\n7gaGgI3ufmW47jLgcmAvsNLd11fd6phKA9zT295gx79vOuAm6yJpqiRHRPIuadfTZ4G33X0hcB7w\nbeB2YIW7LwImmdkFZjYbuAo4M1xvlZlNqUG7YysNbB9WaK9nWJFYOZJlA0XiSloo/g64Mfx9MrAP\nONXdO8JlDwNLgNOADe6+z937gC3A/CraK9Io4uTIOVk0TKRSibqe3H0XgJkVgAeAG4Cvl63SD8wA\nCkBv2fIBoC1OjGKxQE9Pa5LmxdLe3kqxWBgzbhYUd2KJmSOxcyELjRw3jW3HwbYZ1WqEXEg8mG1m\nvwP8PfBtd7/fzL5W9nQB2An0ERSM0cvH1dXVT3f3QNLmjau7e4Curv4DlhWLhfctqwfFrV/ceoqZ\nI+Nqtu+oFnHT2HaMtc2oVqPkQqKup3Ds4VHgi+5+T7j4eTNbGP5+PtABPA0sMLOpZtYGzAM2Jokp\n0kgqyBFJYHBwkFdf3TLyE1y6R9KS9IjieuAI4EYzuwkYBpYD3woHqzcBD7r7sJndAWwAWggG8vbU\noN0ieRcrRzJsX0PT1aDrK+kYxReAL4zx1OIx1l0LrE0SR6RRVZIjkowu1VM/uTzh7pqbvgEtU+jv\nfgP4QNbNEZEMlN9sLM5VoMvX1wm2tZXLQvHsa1NpbZ/De29uhfQmPolIjpW6l4BYXUvl3VE6wba2\nclkoREQg6F4qvxQPBEcXUeu3HjmHXb1v1qN5TUOFQkRyrfxSPKWBa6kvFQoRyT0NXGdLhUJEMlca\niO7paWXGjFkV3b54dNeU1J4KhYgkVunMpIOpdOC63P7bIO/QAHZKVChEJLFqNvCjBbcyrua1w4lf\nL9FUKESkKtVs4KUxqFCICHBgN1KSsYKJbKwpus30f6NCISKArp8UZawpus30f6NCISIjNA314Jr5\n/0aFQkRSUd6VBc3XXTORqFCISNXG6sM/WFdWqYAE95BoYfLkSSOvLX+fsc6N0DkT2WjKQlH+x6a9\nHJHqHewyG2N115QKyO7+HRxWmHnARfzK32esC/vpnIlsNGWhKP2xwYtNNyglkpZK+vBL5z2MdRG/\n8S7sl/U5E824o9mUhQI091uaR63HCpLc92G8LqVG0ow7mk1bKESaxVhjBaUxhJKoS3dHvV/c+z6M\n16XUaEZf/rx8vGUiHmU0daEYPTDW3n5Shq0RSc/obqGxikeS96vkvg8T7V4Ro4vfYYWZQPWXMsmj\n1AuFmbUAfw2cBLwLXObuW6NfVR/lX/Q7O3/DV/5bF21txXH3DjTtT5LKUz5EjSlU0w/fTDOTyovf\nRO7OrscRxX8Bprn7WWZ2OnB7uCwXyr/om+76fyOH04cVZjI8PMQ1f3QKRx99DLA/Ycr3xt7Z+Ruu\n+aNTmDPnKErFpXxdkVFqlg/9/X1s+tVmBgcHGR7ex+xZs8bdyRlrIz7WstJO1PDw8yM5UHrv119/\nLbJdzTwzabxLfYy+2m4lstxBrUehWAA8AuDuPzezj1by4l29b7G7vxtoARj392rWLR06lrw70MMt\nax7j0NZ23h3o5n8sW8LRRx9zwB9CaZ333tnJtMOPeN+6cfT0tNLdPVDJf0tNNGrcBj+sryofyv3f\nf3iCHz63l129bzLQ/RqHtrbT++ZWph1+BMABf6+7et8CoPvXzi1rfsl77+zkiN/+8EGXlfKhPAdK\n7z16vahcKsWNm6tZLavde+/gljW/POh2YPv2bdyy5rGR7+fkk383di6UXlt677u+clndcqFleDjd\naWZmtgZ40N0fDR93Ase6+1CqgUVySPkgjWhSHWL0AYXymEoKaWLKB2k49SgU/wIsBTCzM4CX6xBT\nJK+UD9Jw6jFG8RCwxMz+JXz8x3WIKZJXygdpOKmPUYiISGOrR9eTiIg0MBUKERGJpEIhIiKRVChE\nRCRSrgqFmeWqPSJZUS5InmQ+68nMjiW43s1HgX0Exetl4Gp335xy7CnAfKAN2AlsdPc9Ey1m1rGz\n/MyNJONcuAA4h/3fUQfBGeSaFllDjZqDeSgUTwDXu/vPy5adAdzm7h9LMe7vA6uALcAAwdmy84AV\n7v7DiRIz69hZfuZGk2Eu/BVBUXoY6Cf4js4Hprj7ZWnFLYvfkBvPBPEaNgfzcD+KQ8sTA8Ddf2Zm\nace9AVjg7n2lBWbWBjwOpPWlZREz69iZfWYzmwncSLCnPIP9e8o3u/tbacZOKKtcONHdF41atq7s\npMDUHGwjZmaZbDxTjtuwOZiHQvGimX2X4IqavQRf2FLgpZTjTgF2jVq2m3RvxptFzKxjZ/mZ7wHu\nBW5i/57yUuBvCYpH3mSVC5PM7OPu3lFaYGaLgL0px4UG3ngm0LA5mIdC8d8Jrse/gGCvrw/4CcGl\nDtJ0F/CcmW0gSMoZYRvumGAxs46d5Wee4e4/KHvcB9xvZlfWIXYSWeXCpcDtZva3BNfNng38A5B6\ntxMNvPFMoGFzMPMxiiyZ2WzgNII9tz7gaXdP9T6NWcTMOnaGcR8k2BsfvYd+ortflHb8RmFma939\nT8IbKf0fYAfBxuTS0V1hKcReBlwFvG8j5u5rJ2DcrHNwBsHnrShus0/BOwM4FzgP+CSwMLxV5USL\nmXXsrOJ+lqDL6UvAt4DrCPqjL6lD7EbywfDflcD57n468J+Br6Ud2N3XAEsIBtJfDv/9ZJob6zHi\nbqxXXDLIBTP7w7AoPAmcDCwHrjaz1rjvkYeup0xEzPQ4l5QOubOImXXsLD+zu79rZt8mGMBuA3rQ\n1Nwog+6+BcDdf13HcznOINholyYcHGZmqU7NDTeeD5jZk8D/JNiAPmtmt7h7Krd9zDAXrgAeAP4S\n2Ar8OcGOwF3AxXHeoGkLBdnM9MhsdkmGsZtuRk0DajOzZ4HDzexPCLqfbgO2Rb+seo288Uwgy/wH\n+LC7Lwt/32Rm/zXuC5u5UIw102Mh6c70yCJmVOx6zGxpxhk1DcXdP2Jm04CTCAZ4hwi6gdLuhoEG\n3ngmkFX+f9jMrgb2mdkp7v58eK/2qXHfoJkLxaUcONNjCHieYICrHjEnAUWCPallUS9KKXYb8I+k\nP7OlPG4LwR/n83WIC9lOzW0o7v4e8IuyRX9Tp9BZbzz3Jt14JnAp9d/mAHwKOBX4FTDfzLYC3wau\njvsGzVwo/iNBv+Qe4AZ3vx9Gzo79REoxJwPXEvyRAHxv1OM0LQSeA75M0LXQRfB/MBd4JcW4kwmS\nfgPBdLzvAR8GPpJyXMh2aq7EcynBxvP77N94Pkf6O0+fIvgb3MyBG88rUoyZxTYH4HcIxmH2Ah3u\n3gucUUncZi4UNxAcak8GHjCzae5+D+lutB8n2MP9dRjnePbvuaX5hwLBHP3FwDrg0+6+2cw+APwo\nbFda1gBfITiC+THB//nOMOYPIl5XNXdfY2brOHA64pfrNR1ZxufurwIXZBD3BeAFDuxeOyPlsFls\nc0pxTyboSUgUt5kLxR533wkjF0R7wsy2k263xEcJCsOd7v6YmT3p7mkXiJK97v6OmfUTDN6VZrak\n3Q1ziLs/Hk4B/Kq7vw5gZvUYo4AMZtRIfOGso2ljPefuZ02wuFlsc0pxe6qJ28yFotPMbgdudPf+\ncBDrUeCItAK6+1tmdhHwdTP7T2nFOYh1ZvYjgjnjPzGzRwnmcj+RctxOM7uf4G9twMxWEnQDvZFy\n3Eyn5kps1xEcdV5IcMXciRy37tucWsVt5kLxeYITsoYB3P01MzsbuD7NoO6+D/iCmV1KHU94dPdb\nw9lG5wLbgVkEZ6GuTzn0JQRnQ28mmKJ6NUH32+dTjgvZz6iRcbj7z83sXmC+u6d9qZKs42ayzalF\n3Ka+hIdMbGbWQXAp5dEzar7s7osza5hIg2nmIwqZ+C4lmxk1IhOKjihERCSSjihkwspqRo3IRKNC\nIRNZVjNqRCYUdT3JhGZm1wKv1HNGjchEo0IhIiKRmv3GRSIiMg4VChERiaRCISIikVQoREQk0v8H\nCbFzqXQK90MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a701190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages.hist(column='length', by='label', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przetworzenie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (5574, 13627)\n",
      "number of non-zeros: 80164\n",
      "sparsity: 0.11%\n"
     ]
    }
   ],
   "source": [
    "messages_bow = # Twoj kod, bow = bag of words.\n",
    "print 'sparse matrix shape:', messages_bow.shape\n",
    "print 'number of non-zeros:', messages_bow.nnz\n",
    "print 'sparsity: %.2f%%' % (100.0 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_detector = # Twoj kod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.993003229279\n",
      "confusion matrix\n",
      "[[4813   14]\n",
      " [  25  722]]\n",
      "(row=expected, col=predicted)\n"
     ]
    }
   ],
   "source": [
    "print 'accuracy', # Twoj kod\n",
    "print 'confusion matrix\\n', # Twoj kod"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
